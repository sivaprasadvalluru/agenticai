{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nn3P78iQSx7M"
   },
   "source": [
    "# In this lab, you will understand how to use vector stores and RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBR_pYFrQ-6q"
   },
   "source": [
    "**STORING DOCUMENTS IN CHROMA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lvui4q2yRj1n"
   },
   "outputs": [],
   "source": [
    "pip install langchain-huggingface  langchain_core langchain_openai langchain_chroma langchain_community faiss-cpu pypdf gradio langsmith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1a1NdNFWSx7R"
   },
   "source": [
    "\n",
    "\n",
    "**Open .env file in this folder and observe that we have configured OPENAI_API_KEY. Replace it with your own key or key given by me**\n",
    "\n",
    "The Code in the below cell will load the .env file and set environment variables.\n",
    "\n",
    "**Write the code in the below cell and execute it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1732888786200,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "qjTVbkyGQhAI",
    "outputId": "6156a0a3-5b02-445e-b906-b22375e76cb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2uaTSDMSx7T"
   },
   "source": [
    "**Creating Documents manually**\n",
    "\n",
    " **Document**  represents a unit of text and associated metadata.\n",
    "\n",
    " It has two attributes:\n",
    "\n",
    "**pagecontent** string representing the content\n",
    "\n",
    "**metadata** a dict containing arbitrary metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JozLF9M_SOyX"
   },
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\",\n",
    "        metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\",\n",
    "        metadata={\"year\": 2010, \"director\": \"Christopher Nolan\", \"rating\": 8.2},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\",\n",
    "        metadata={\"year\": 2006, \"director\": \"Satoshi Kon\", \"rating\": 8.6},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A bunch of normal-sized women are supremely wholesome and some men pine after them\",\n",
    "        metadata={\"year\": 2019, \"director\": \"Greta Gerwig\", \"rating\": 8.3},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Toys come alive and have a blast doing so\",\n",
    "        metadata={\"year\": 1995, \"genre\": \"animated\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Three men walk into the Zone, three men walk out of the Zone\",\n",
    "        metadata={\n",
    "            \"year\": 1979,\n",
    "            \"director\": \"Andrei Tarkovsky\",\n",
    "            \"genre\": \"thriller\",\n",
    "            \"rating\": 9.9,\n",
    "        },\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIGxN7ZESXVO"
   },
   "source": [
    "# **Creating  a vector store(Chroma) and Persisting Documents using OpenAIEmbeddings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADpNyNTtSx7U"
   },
   "source": [
    "**Chroma is a AI-native open-source vector database**\n",
    "\n",
    "Chroma runs in various modes:\n",
    "\n",
    "**in-memory**\n",
    "\n",
    "**in-memory with persistance**  - in a script or notebook and save/load to disk\n",
    "\n",
    "**in a docker container** -- as a server running your local machine or in the cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gmbf5BGLSx7U"
   },
   "source": [
    "Below code creates a vectorstore from the given documents and persists data in given directory.\n",
    "\n",
    "Execute the below code and observe that a directory with name chromadb1 is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZmVj9G7fST62"
   },
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "#embeddings = OpenAIEmbeddings()\n",
    "\n",
    "embeddings= HuggingFaceEmbeddings()\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents, embedding=embeddings , persist_directory=\"chromadb4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvbLnFPRqI9C"
   },
   "source": [
    "**Let us understand how to create a vector store using the persist_directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "N50WUupdqXoy"
   },
   "outputs": [],
   "source": [
    "vectorstore = Chroma(\n",
    "    persist_directory=\"chromadb4\", embedding_function=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6ZKX6cdrG4B"
   },
   "source": [
    "**Using Vector Store as a retriever**\n",
    "\n",
    "LangChain VectorStore objects do not subclass Runnable\n",
    "LangChain Retrievers are Runnables. So, we can use them in chains in LCEL\n",
    "\n",
    "Vectorstores implement an **as_retriever** method that will generate a Retriever, specifically a **VectorStoreRetriever**\n",
    "\n",
    "Below code shows how to get a retriever from vectorstore object\n",
    "see the documentation at (https://api.python.langchain.com/en/latest/vectorstores/langchain_community.vectorstores.chroma.Chroma.html#langchain_community.vectorstores.chroma.Chroma.as_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AnXMQRBprFBo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='6b6f83ea-3723-4883-9b69-d5831a761463', metadata={'director': 'Satoshi Kon', 'rating': 8.6, 'year': 2006}, page_content='A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",  # mmr or similarity_score_threshold\n",
    "    search_kwargs={\"k\": 1},\n",
    ")\n",
    "\n",
    "retriever.invoke(\"tell me about movie directed by Satoshi Kon\")\n",
    "\n",
    "#result4 = retriever.batch([\"Scientist\",\"toys\"])\n",
    "#print(result4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unAGEHz5uEY4"
   },
   "source": [
    "## Now let us see how to load a PDF into vector store and persist it.  This time we will use FAISS\n",
    "\n",
    " We will be using PyPdfLoader to load documents from pdf.\n",
    "\n",
    " There many document loaders available. See (https://api.python.langchain.com/en/latest/community_api_reference.html#module-langchain_community.document_loaders)\n",
    "\n",
    "<font color=\"red\"> **Before executing below code, travel.pdf  given to u**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 2765,
     "status": "ok",
     "timestamp": 1737019902619,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "wx8iU3X5uUEY"
   },
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "\n",
    "#loader = PyPDFLoader(file_path=\"drive/MyDrive/Colab Notebooks/ds-book.pdf\")\n",
    "loader = PyPDFLoader(file_path=\"travel-policy.pdf\")\n",
    "documents = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1554,
     "status": "ok",
     "timestamp": 1737019927008,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "yL2OMQJOdGG0",
    "outputId": "9cb90059-413c-4bd7-de26-5ba59756dbb2"
   },
   "outputs": [],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmbaShzJSx7W"
   },
   "source": [
    "**After all documents are loaded, we have to split them into chunks.**\n",
    "\n",
    "**Observe the below code and understand how we are splitting documents in to chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 578,
     "status": "ok",
     "timestamp": 1737019992681,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "WB_A2yWNSx7W"
   },
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=50, separator=\"\\n\")\n",
    "docs = text_splitter.split_documents(documents=documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmbaShzJSx7W"
   },
   "source": [
    "**Observe the below code and understand how we are using **FAISS** to create vector store and save the documents**\n",
    "\n",
    "**Execute the below code in a cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "eC0K0MMSSx7W"
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "#embeddings = OpenAIEmbeddings()\n",
    "\n",
    "embeddings= HuggingFaceEmbeddings()\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "vectorstore.save_local(\"faiss_store1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZ2zBlzcsa_4"
   },
   "source": [
    "**Creating a Retrieval Chain using Vector Store as retriever**\n",
    "\n",
    "see the below code and understand how we are creating a retrieval chain using vector store as retirver\n",
    "\n",
    "Execute the below code to  create a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-hInDt-sYhh"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.combine_documents.stuff import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "vectorstore = FAISS.load_local(\n",
    "    \"faiss_store1\", embeddings=embeddings, allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",  # mmr or similarity_score_threshold\n",
    "    search_kwargs={\"k\": 3},\n",
    ")\n",
    "message = \"\"\"\n",
    "        Answer this question using the provided context only.\n",
    "        If the information is not available in the context, just reply with \"i dont know\"\n",
    "        {input}\n",
    "        Context:\n",
    "        {context}\n",
    "        \"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"human\", message)],\n",
    ")\n",
    "llm = ChatOpenAI()\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "#print(question_answer_chain)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "print(rag_chain)\n",
    "\n",
    "# rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm\n",
    "# rag_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etN1l7Eont7Q"
   },
   "source": [
    "**<font color=\"red\"> Understand about create_map_reduce_documents_chain,create_refine_documents_chain,create_map_rerank_documents_chain.  Better u chat gpt to get summary of usecases,usage,etc**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1aqjXSz1th-G"
   },
   "source": [
    "**Invoking Retrieval chain**\n",
    "\n",
    "Execute the below code to invoke the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DAlL5W3etvay"
   },
   "outputs": [],
   "source": [
    "response = rag_chain.invoke({\"input\": \"tell me about all the reimbursement policies\"})\n",
    "print(response)\n",
    "print(response['answer'])\n",
    "for  doc in response[\"context\"]:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3KaMQ5_Sx7X"
   },
   "source": [
    "# BUILDING AN APP SIMILAR TO CHATPDF\n",
    "\n",
    "We want to build an app similar to chatpdf.\n",
    "We need a function which will take a file, and store all the documents into vectorstore\n",
    "\n",
    "Understand the below function and execute it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "w6oTWXAGsHtC"
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "def load_pdf_into_vectorstore(file: tempfile) -> str:\n",
    "    try:\n",
    "        print(\"======Loading file==================\")\n",
    "        file_path = file.name\n",
    "        loader = PyPDFLoader(file_path=file_path)\n",
    "        documents = loader.load()\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=30, separator=\"\\n\")\n",
    "        docs = text_splitter.split_documents(documents=documents)\n",
    "        embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "        #vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "\n",
    "        vectorstore = Chroma.from_documents(\n",
    "            documents, embedding=embeddings , persist_directory=\"chromadb11\"\n",
    "        )\n",
    "       # vectorstore.save_local(\"pdf_store\")\n",
    "\n",
    "        print(\"======File Loaded================== \")\n",
    "\n",
    "        return 'Document uploaded and index created successfully. You can chat now.'\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfcc1fPSxbo_"
   },
   "source": [
    "**Now let us build an app using gradio which allows to upload pdf and chat**\n",
    "\n",
    "in the below code, we are defining a function which will be invoked when user sends a message to chatbot.\n",
    "\n",
    "Understand the code in the below cell and execute it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "eYJjdL8Sp1WZ"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from langchain import OpenAI, PromptTemplate\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "\n",
    "def getresponse(query, history:list) -> tuple:\n",
    "\n",
    "   vectorstore = Chroma(\n",
    "      persist_directory=\"chromadb11\", embedding_function=embeddings\n",
    "  )\n",
    "\n",
    " #  vectorstore = FAISS.load_local(\"pdf_store\", embeddings= OpenAIEmbeddings(), allow_dangerous_deserialization=True)\n",
    "\n",
    "   message = \"\"\"\n",
    "    Answer this question using the provided context . If information is not available in the context,\n",
    "      Just respond saying \"I dont know\"\n",
    "    {input}\n",
    "    Context:\n",
    "    {context}\n",
    "    \"\"\"\n",
    "\n",
    "   prompt = ChatPromptTemplate.from_messages([(\"human\", message)])\n",
    "   llm = ChatOpenAI()\n",
    "\n",
    "\n",
    "   question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "#print(question_answer_chain)\n",
    "   rag_chain = create_retrieval_chain(vectorstore.as_retriever(), question_answer_chain)\n",
    "\n",
    "   # rag_chain = (\n",
    "   #    {\"context\": vectorstore.as_retriever(), \"question\": RunnablePassthrough()}\n",
    "   #    | prompt\n",
    "   #    | llm\n",
    "   # )\n",
    "\n",
    "\n",
    "\n",
    "   response1= rag_chain.invoke({\"input\":query})\n",
    "   print(response1)\n",
    "   history.append((query, response1['answer']))\n",
    "   return \"\",history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkzxdQB2Sx7X"
   },
   "source": [
    "**Understand and execute the below code.**\n",
    "\n",
    "**Once u go to the given url , upload a file and send queries and chat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YvlTLA0BSx7Y"
   },
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            file = gr.components.File(\n",
    "                label='Upload your pdf file',\n",
    "                file_count='single',\n",
    "                file_types=['.pdf'])\n",
    "            #with gr.Row():\n",
    "            upload = gr.components.Button(\n",
    "                    value='Upload', variant='primary')\n",
    "\n",
    "        label = gr.components.Textbox()\n",
    "    chatbot = gr.Chatbot(label='Talk to the Document')\n",
    "\n",
    "\n",
    "    msg = gr.Textbox()\n",
    "    clear = gr.ClearButton([msg, chatbot])\n",
    "    vectorStore =None\n",
    "\n",
    "    upload.click(load_pdf_into_vectorstore,[file],[label])\n",
    "\n",
    "    msg.submit(getresponse, [msg,chatbot], [msg, chatbot])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nz-bd-WWy2Sk"
   },
   "source": [
    "**Let us try to understand how to retrieve data from a given web url**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "75P1He5HzDF2"
   },
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load blog post\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "data = loader.load()\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "splits = text_splitter.split_documents(data)\n",
    "\n",
    "# VectorDB\n",
    "embedding = HuggingFaceEmbeddings()\n",
    "vectordb = Chroma.from_documents(documents=splits, embedding=embedding)\n",
    "vectordb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AahTb8F7yliA"
   },
   "source": [
    "**Now Let us try to Understand MultiQueryRetriever**\n",
    "\n",
    "The MultiQueryRetriever automates the process of prompt tuning by using an LLM to generate multiple queries from different perspectives for a given user input query. For each query, it retrieves a set of relevant documents and takes the unique union across all queries to get a larger set of potentially relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IbXiUhyLyuGT"
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectordb.as_retriever(), llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prKUqTeMzU7v"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-mEsFZpzXHY"
   },
   "outputs": [],
   "source": [
    "unique_docs = retriever_from_llm.invoke(question)\n",
    "unique_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gks5lkYeSx7c"
   },
   "source": [
    "**(Optional)See how to build  conversational rag at https://python.langchain.com/docs/how_to/qa_chat_history_how_to/**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
